{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atedi\\OneDrive\\Documents\\SageBionetworks\\synapse\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## imports ##\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, decomposition, tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.feature_selection import RFECV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "\n",
    "- Gait data being used is based on the PDKit mPowerV1 data, collapsed by each healthCode ids\n",
    "- Features chosen are based on a feature_engineering.ipnb\n",
    "- For this ML Analysis, we will split the training-test set by 20%\n",
    "- Parameters will be searched through grid search (GridSearchCV) and the score is assessed using Stratified 10-Fold Validation \n",
    "- Models being used: Logistic Regression, Xtreme Gradient Boost, Sklearn Gradient Boost and Random Forests\n",
    "- Feature elimination will be done on several model using recursive feature elimination CV (Sklearn RFECV package)\n",
    "- Learning Curves of each model (Work in progress)\n",
    "- Best model will be dump into .pkl file (Work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_fit(X_train, y_train):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(random_state = 100))\n",
    "        ])\n",
    "    param = [{'classifier__penalty': ['l2'], \n",
    "              'classifier__solver': [ 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}, \n",
    "             {'classifier__penalty': ['l1'], \n",
    "              'classifier__solver': [ 'liblinear', 'saga']}  \n",
    "            ]\n",
    "\n",
    "    CV = GridSearchCV(estimator = pipe, param_grid = param , scoring= \"roc_auc\", n_jobs = 1, cv = 10)\n",
    "    CV.fit(X_train, y_train)\n",
    "    return CV\n",
    "\n",
    "\n",
    "\n",
    "def xgb_fit(X_train, y_train):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', XGBClassifier(seed = 100, nthread = -1))\n",
    "        ])\n",
    "    param = {\n",
    "        \"classifier__learning_rate\" : [0.01, 0.05, 0.1],\n",
    "        \"classifier__tree_method\"   : [\"hist\", \"auto\"],\n",
    "        \"classifier__max_depth\"     : [3, 6, 8],\n",
    "        \"classifier__gamma\"         : [1],\n",
    "        \"classifier__subsample\"     : [0.8],\n",
    "        \"classifier__n_estimators\"  : [100]\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = pipe, param_grid = param , scoring= \"roc_auc\", n_jobs = 1, cv = 10)\n",
    "    CV.fit(X_train, y_train)\n",
    "    return CV\n",
    "    \n",
    "\n",
    "def gradientboost_fit(X_train, y_train):\n",
    "    pca = decomposition.PCA()\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', GradientBoostingClassifier(random_state = 100, warm_start = True))\n",
    "        ])\n",
    "    param = {\n",
    "        'classifier__learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'classifier__max_depth':[1, 2, 3, 4, 5, 6],\n",
    "        'classifier__loss': [\"deviance\", \"exponential\"], ## exponential will result in adaBoost\n",
    "        \"classifier__n_estimators\"  : [100]\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = pipe, param_grid = param , scoring= \"roc_auc\", n_jobs = 1, cv = 10)\n",
    "    CV.fit(X_train, y_train)\n",
    "    return CV\n",
    "\n",
    "def randomforest_fit(X_train, y_train):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(random_state = 100))\n",
    "        ])\n",
    "    param = {\n",
    "        'classifier__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'classifier__criterion': [\"gini\", \"entropy\"],## exponential will result in adaBoost\n",
    "        'classifier__max_features': [\"auto\", \"sqrt\", \"log2\", None], \n",
    "        'classifier__n_estimators'  : [100, 200]\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = pipe, param_grid = param , scoring= \"roc_auc\", n_jobs = 1, cv = 10)\n",
    "    CV.fit(X_train, y_train)\n",
    "    return CV\n",
    "\n",
    "\n",
    "def printPerformance(model, X_test, y_test):\n",
    "    print(\"Mean AUC score on K-folds: {}\".format(model.best_score_))\n",
    "    print(\"Parameter Used: {}\".format(model.best_params_))\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(\"ROC-AUC on Test-Set: {}\".format(metrics.roc_auc_score(y_true, y_pred)))\n",
    "    print(\"log-loss: {}\".format(metrics.log_loss(y_true, y_pred)))\n",
    "    print(\"Precision: {}\".format(metrics.precision_score(y_true, y_pred)))\n",
    "    print(\"Recall: {}\".format(metrics.recall_score(y_true, y_pred)))\n",
    "    print(\"F1-Score: {}\".format(metrics.f1_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_train = pd.read_csv(\"../Data/walking_data_training.csv\", index_col=0)\n",
    "walking_train_imputed = pd.read_csv(\"../Data/walking_imputed.csv\", index_col=0)\n",
    "walking_test_imputed = pd.read_csv(\"../Data/walking_imputed_test_data.csv\", index_col=0)\n",
    "balance_train = pd.read_csv(\"../Data/balance_data_training.csv\", index_col=0).dropna()\n",
    "balance_X_train, balance_X_test, balance_y_train, balance_y_test = train_test_split(balance_train.drop([\"healthCode\", \"PD\"], axis = 1), balance_train[\"PD\"], test_size=0.20, random_state = 100)\n",
    "walking_X_train, walking_X_test, walking_y_train, walking_y_test = train_test_split(walking_train.drop([\"healthCode\", \"PD\"], axis = 1), walking_train[\"PD\"], test_size=0.20, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model on Walking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Gradient Boosting Walking ###\n",
      "Mean AUC score on K-folds: 0.6869747899159663\n",
      "Parameter Used: {'classifier__learning_rate': 0.1, 'classifier__loss': 'deviance', 'classifier__max_depth': 6, 'classifier__n_estimators': 100}\n",
      "ROC-AUC on Test-Set: 0.7619047619047619\n",
      "log-loss: 7.970548367858634\n",
      "Precision: 0.8\n",
      "Recall: 0.6666666666666666\n",
      "F1-Score: 0.7272727272727272\n",
      "\n",
      "### XTreme Gradient Boosting Walking ###\n",
      "Mean AUC score on K-folds: 0.6935107376283847\n",
      "Parameter Used: {'classifier__gamma': 1, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 8, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8, 'classifier__tree_method': 'hist'}\n",
      "ROC-AUC on Test-Set: 0.6547619047619049\n",
      "log-loss: 11.51300747496307\n",
      "Precision: 0.6923076923076923\n",
      "Recall: 0.5\n",
      "F1-Score: 0.5806451612903226\n",
      "\n",
      "### Random Forest Walking ###\n",
      "Mean AUC score on K-folds: 0.7049486461251168\n",
      "Parameter Used: {'classifier__criterion': 'gini', 'classifier__max_depth': 3, 'classifier__max_features': 'auto', 'classifier__n_estimators': 100}\n",
      "ROC-AUC on Test-Set: 0.7341269841269842\n",
      "log-loss: 8.856158019010191\n",
      "Precision: 0.7857142857142857\n",
      "Recall: 0.6111111111111112\n",
      "F1-Score: 0.6875000000000001\n",
      "\n",
      "### Logistic Regression Walking ###\n",
      "Mean AUC score on K-folds: 0.6458916900093371\n",
      "Parameter Used: {'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "ROC-AUC on Test-Set: 0.7103174603174603\n",
      "log-loss: 9.741788172659957\n",
      "Precision: 0.7333333333333333\n",
      "Recall: 0.6111111111111112\n",
      "F1-Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "lr_walking_model = logreg_fit(walking_X_train, walking_y_train)\n",
    "rf_walking_model = randomforest_fit(walking_X_train, walking_y_train)\n",
    "gb_walking_model = gradientboost_fit(walking_X_train, walking_y_train)\n",
    "xgb_walking_model = xgb_fit(walking_X_train, walking_y_train)\n",
    "\n",
    "\n",
    "print(\"\\n### Gradient Boosting Walking ###\")\n",
    "printPerformance(gb_walking_model, walking_X_test.dropna(), walking_y_test.dropna())\n",
    "print(\"\\n### XTreme Gradient Boosting Walking ###\")\n",
    "printPerformance(xgb_walking_model, walking_X_test.dropna(), walking_y_test.dropna())\n",
    "print(\"\\n### Random Forest Walking ###\")\n",
    "printPerformance(rf_walking_model, walking_X_test.dropna(), walking_y_test.dropna())\n",
    "print(\"\\n### Logistic Regression Walking ###\")\n",
    "printPerformance(lr_walking_model, walking_X_test.dropna(), walking_y_test.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78        25\n",
      "           1       0.61      0.79      0.69        14\n",
      "\n",
      "    accuracy                           0.74        39\n",
      "   macro avg       0.73      0.75      0.74        39\n",
      "weighted avg       0.77      0.74      0.75        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(rf_walking_model.predict(walking_X_test), walking_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1\n",
       "Actual           \n",
       "0          18   7\n",
       "1           3  11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(rf_walking_model.predict(walking_X_test), walking_y_test, rownames = [\"Actual\"], colnames = [\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_median_freeze_index accel_walking_features_x        0.165895\n",
       "max_gait_symmetry userAccel_walking_features_z          0.132659\n",
       "max_median_freeze_index accel_walking_features_z        0.124324\n",
       "max_count_freeze_index userAccel_walking_features_AA    0.116638\n",
       "max_median_freeze_index userAccel_walking_features_x    0.100786\n",
       "max_median_freeze_index accel_walking_features_AA       0.079038\n",
       "max_gait_symmetry userAccel_walking_features_x          0.070303\n",
       "max_count_freeze_index userAccel_walking_features_z     0.066463\n",
       "max_count_freeze_index userAccel_walking_features_x     0.055631\n",
       "max_median_freeze_index accel_walking_features_y        0.049956\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model Feature Importances by Gini Index\n",
    "pd.Series(data = rf_walking_model.best_estimator_[1].feature_importances_, index = walking_X_test.columns).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_gait_symmetry userAccel_walking_features_z          0.176044\n",
       "max_median_freeze_index accel_walking_features_z        0.156939\n",
       "max_median_freeze_index accel_walking_features_x        0.152922\n",
       "max_count_freeze_index userAccel_walking_features_z     0.110416\n",
       "max_count_freeze_index userAccel_walking_features_AA    0.103573\n",
       "max_count_freeze_index userAccel_walking_features_y     0.084524\n",
       "max_median_freeze_index accel_walking_features_AA       0.064938\n",
       "max_median_freeze_index accel_walking_features_y        0.053581\n",
       "max_gait_symmetry userAccel_walking_features_x          0.038694\n",
       "max_count_freeze_index userAccel_walking_features_x     0.034383\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model Feature Importances\n",
    "pd.Series(data = gb_walking_model.best_estimator_[1].feature_importances_, index = walking_X_test.columns).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synapse",
   "language": "python",
   "name": "synapse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
