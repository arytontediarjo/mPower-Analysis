{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atedi\\OneDrive\\Documents\\SageBionetworks\\synapse\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## imports ##\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, decomposition, tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.feature_selection import RFECV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "\n",
    "- Gait data being used is based on the PDKit mPowerV1 data, collapsed by each healthCode ids\n",
    "- Features chosen are based on a feature_engineering.ipnb\n",
    "- For this ML Analysis, we will split the training-test set by 20%\n",
    "- Parameters will be searched through grid search (GridSearchCV) and the score is assessed using Stratified 10-Fold Validation \n",
    "- Models being used: Logistic Regression, Xtreme Gradient Boost, Sklearn Gradient Boost and Random Forests\n",
    "- Feature elimination will be done on several model using recursive feature elimination CV (Sklearn RFECV package)\n",
    "- Learning Curves of each model (Work in progress)\n",
    "- Best model will be dump into .pkl file (Work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_fit(X_train, y_train):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(random_state = 100))\n",
    "        ])\n",
    "    param = [{'classifier__penalty': ['l2'], \n",
    "              'classifier__solver': [ 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}, \n",
    "             {'classifier__penalty': ['l1'], \n",
    "              'classifier__solver': [ 'liblinear', 'saga']}  \n",
    "            ]\n",
    "\n",
    "    CV = GridSearchCV(estimator = pipe, param_grid = param , scoring= \"roc_auc\", n_jobs = 1, cv = 10)\n",
    "    CV.fit(X_train, y_train)\n",
    "    return CV\n",
    "\n",
    "\n",
    "\n",
    "def xgb_fit(X_train, y_train):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('classifier', XGBClassifier(seed = 100))\n",
    "        ])\n",
    "    param = {\n",
    "        \"classifier__learning_rate\" : [0.01, 0.05, 0.1],\n",
    "        \"classifier__tree_method\"   : [\"hist\", \"auto\"],\n",
    "        \"classifier__max_depth\"     : [6, 8],\n",
    "        \"classifier__gamma\"         : [0, 1],\n",
    "        \"classifier__subsample\"     : [0.8],\n",
    "        \"classifier__n_estimators\"  : [100]\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = pipe, param_grid = param , scoring= \"roc_auc\", n_jobs = 1, cv = 10)\n",
    "    CV.fit(X_train, y_train)\n",
    "    return CV\n",
    "    \n",
    "\n",
    "def gradientboost_fit(X_train, y_train):\n",
    "    pca = decomposition.PCA()\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', GradientBoostingClassifier(random_state = 100, warm_start = True))\n",
    "        ])\n",
    "    param = {\n",
    "        'classifier__learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'classifier__max_depth':[1, 2, 3, 4, 5, 6],\n",
    "        'classifier__loss': [\"deviance\", \"exponential\"], ## exponential will result in adaBoost\n",
    "        \"classifier__n_estimators\"  : [100]\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = pipe, param_grid = param , scoring= \"roc_auc\", n_jobs = 1, cv = 10)\n",
    "    CV.fit(X_train, y_train)\n",
    "    return CV\n",
    "\n",
    "def randomforest_fit(X_train, y_train):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(random_state = 100))\n",
    "        ])\n",
    "    param = {\n",
    "        'classifier__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'classifier__criterion': [\"gini\", \"entropy\"],## exponential will result in adaBoost\n",
    "        'classifier__max_features': [\"auto\", \"sqrt\", \"log2\", None], \n",
    "        'classifier__n_estimators'  : [100, 200]\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = pipe, param_grid = param , scoring= \"roc_auc\", n_jobs = 1, cv = 10)\n",
    "    CV.fit(X_train, y_train)\n",
    "    return CV\n",
    "\n",
    "\n",
    "def printPerformance(model, X_test, y_test):\n",
    "    print(\"Mean AUC score on K-folds: {}\".format(model.best_score_))\n",
    "    print(\"Parameter Used: {}\".format(model.best_params_))\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(\"ROC-AUC on Test-Set: {}\".format(metrics.roc_auc_score(y_true, y_pred)))\n",
    "    print(\"log-loss: {}\".format(metrics.log_loss(y_true, y_pred)))\n",
    "    print(\"Precision: {}\".format(metrics.precision_score(y_true, y_pred)))\n",
    "    print(\"Recall: {}\".format(metrics.recall_score(y_true, y_pred)))\n",
    "    print(\"F1-Score: {}\".format(metrics.f1_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_train = pd.read_csv(\"../Data/walking_data_training.csv\", index_col=0)\n",
    "walking_train_imputed = pd.read_csv(\"../Data/walking_imputed.csv\", index_col=0)\n",
    "walking_test_imputed = pd.read_csv(\"../Data/walking_imputed_test_data.csv\", index_col=0)\n",
    "balance_train = pd.read_csv(\"../Data/balance_data_training.csv\", index_col=0).dropna()\n",
    "balance_X_train, balance_X_test, balance_y_train, balance_y_test = train_test_split(balance_train.drop([\"healthCode\", \"PD\"], axis = 1), balance_train[\"PD\"], test_size=0.20, random_state = 100)\n",
    "walking_X_train, walking_X_test, walking_y_train, walking_y_test = train_test_split(walking_train.drop([\"healthCode\", \"PD\"], axis = 1), walking_train[\"PD\"], test_size=0.20, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model on Walking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Gradient Boosting Walking ###\n",
      "Mean AUC score on K-folds: 0.6734360410830998\n",
      "Parameter Used: {'classifier__learning_rate': 0.1, 'classifier__loss': 'exponential', 'classifier__max_depth': 2, 'classifier__n_estimators': 100}\n",
      "ROC-AUC on Test-Set: 0.6785714285714286\n",
      "log-loss: 10.627377321313302\n",
      "Precision: 0.75\n",
      "Recall: 0.5\n",
      "F1-Score: 0.6\n",
      "\n",
      "### XTreme Gradient Boosting Walking ###\n",
      "Mean AUC score on K-folds: 0.6429738562091504\n",
      "Parameter Used: {'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 6, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8, 'classifier__tree_method': 'auto'}\n",
      "ROC-AUC on Test-Set: 0.7658730158730158\n",
      "log-loss: 7.9705688703568445\n",
      "Precision: 0.7647058823529411\n",
      "Recall: 0.7222222222222222\n",
      "F1-Score: 0.7428571428571428\n",
      "\n",
      "### Random Forest Walking ###\n",
      "Mean AUC score on K-folds: 0.6748366013071895\n",
      "Parameter Used: {'classifier__criterion': 'gini', 'classifier__max_depth': 7, 'classifier__max_features': 'auto', 'classifier__n_estimators': 200}\n",
      "ROC-AUC on Test-Set: 0.7023809523809524\n",
      "log-loss: 9.741747167663535\n",
      "Precision: 0.8181818181818182\n",
      "Recall: 0.5\n",
      "F1-Score: 0.6206896551724137\n"
     ]
    }
   ],
   "source": [
    "# lr_walking_model = logreg_fit(walking_X_train, walking_y_train)\n",
    "rf_walking_model = randomforest_fit(walking_X_train, walking_y_train)\n",
    "gb_walking_model = gradientboost_fit(walking_X_train, walking_y_train)\n",
    "xgb_walking_model = xgb_fit(walking_X_train, walking_y_train)\n",
    "\n",
    "\n",
    "print(\"\\n### Gradient Boosting Walking ###\")\n",
    "printPerformance(gb_walking_model, walking_X_test.dropna(), walking_y_test.dropna())\n",
    "print(\"\\n### XTreme Gradient Boosting Walking ###\")\n",
    "printPerformance(xgb_walking_model, walking_X_test.dropna(), walking_y_test.dropna())\n",
    "print(\"\\n### Random Forest Walking ###\")\n",
    "printPerformance(rf_walking_model, walking_X_test.dropna(), walking_y_test.dropna())\n",
    "# print(\"\\n### Logistic Regression Walking ###\")\n",
    "# printPerformance(lr_walking_model, walking_X_test.dropna(), walking_y_test.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76        24\n",
      "           1       0.61      0.73      0.67        15\n",
      "\n",
      "    accuracy                           0.72        39\n",
      "   macro avg       0.71      0.72      0.71        39\n",
      "weighted avg       0.73      0.72      0.72        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(xgb_walking_model.predict(walking_X_test), walking_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_test = xgb_walking_model.best_estimator_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_test = XGBClassifier(random_state = 100, warm_start = True, \n",
    "                        gamma= 1, \n",
    "                        learning_rate= 0.1, \n",
    "                        max_depth= 6, \n",
    "                        n_estimators= 100, \n",
    "                        subsample= 0.8, \n",
    "                        tree_method= 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=100,\n",
       "              silent=None, subsample=0.8, tree_method='auto', verbosity=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_test.fit(walking_X_train, walking_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74        25\n",
      "           1       0.56      0.71      0.63        14\n",
      "\n",
      "    accuracy                           0.69        39\n",
      "   macro avg       0.68      0.70      0.68        39\n",
      "weighted avg       0.72      0.69      0.70        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(gb_test.predict(walking_X_test), walking_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1\n",
       "Actual           \n",
       "0          17   7\n",
       "1           4  11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(xgb_walking_model.predict(walking_X_test), walking_y_test, rownames = [\"Actual\"], colnames = [\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_gait_symmetry userAccel_walking_features_z           0.142085\n",
       "max_count_freeze_index userAccel_walking_features_AA     0.114956\n",
       "max_median_freeze_index userAccel_walking_features_x     0.110739\n",
       "max_gait_symmetry userAccel_walking_features_x           0.108403\n",
       "max_median_freeze_index userAccel_walking_features_y     0.100008\n",
       "max_median_freeze_index userAccel_walking_features_z     0.096129\n",
       "max_median_freeze_index userAccel_walking_features_AA    0.095363\n",
       "max_count_freeze_index userAccel_walking_features_x      0.084788\n",
       "max_count_freeze_index userAccel_walking_features_z      0.084549\n",
       "max_count_freeze_index userAccel_walking_features_y      0.062980\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model Feature Importances by Gini Index\n",
    "pd.Series(data = rf_walking_model.best_estimator_[1].feature_importances_, index = walking_X_test.columns).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_gait_symmetry userAccel_walking_features_z           0.124205\n",
       "max_gait_symmetry userAccel_walking_features_x           0.115634\n",
       "max_count_freeze_index userAccel_walking_features_AA     0.113101\n",
       "max_median_freeze_index userAccel_walking_features_y     0.105339\n",
       "max_median_freeze_index userAccel_walking_features_x     0.103012\n",
       "max_count_freeze_index userAccel_walking_features_z      0.097726\n",
       "max_count_freeze_index userAccel_walking_features_x      0.089981\n",
       "max_median_freeze_index userAccel_walking_features_AA    0.088138\n",
       "max_count_freeze_index userAccel_walking_features_y      0.085182\n",
       "max_median_freeze_index userAccel_walking_features_z     0.077680\n",
       "dtype: float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model Feature Importances\n",
    "pd.Series(data = xgb_walking_model.best_estimator_[1].feature_importances_, index = walking_X_test.columns).nlargest(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synapse",
   "language": "python",
   "name": "synapse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
